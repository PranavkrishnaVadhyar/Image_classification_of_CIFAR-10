# -*- coding: utf-8 -*-
"""Copy of CIFAR_CNN_fixed curves.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R1kj4HDc-qrlDuhVjMiW68IRamdzheWr
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout
from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout

# Display the version
print(tf.__version__)

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

physical_devices = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')

for device in physical_devices:
    tf.config.experimental.set_memory_growth(device, True)

# Load in the data
cifar10 = tf.keras.datasets.cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)

"""# Preprocessing"""

# Reduce pixel values
x_train, x_test = x_train / 255.0, x_test / 255.0

# flatten the label values
y_train, y_test = y_train.flatten(), y_test.flatten()

"""We can visualize it in a subplot grid form. Since the image size is just 32×32 so don’t expect much from the image. It would be a blurred one. We can do the visualization using the subplot() function from matplotlib and looping over the first 25 images from our training dataset portion."""

# visualize data by plotting images
fig, ax = plt.subplots(5, 5)
k = 0

for i in range(5):
	for j in range(5):
		ax[i][j].imshow(x_train[k], aspect='auto')
		k += 1

plt.show()

"""classes --
automobile : 1
bird : 2
cat : 3
deer : 4
dog : 5
frog : 6
horse : 7
ship : 8
truck : 9
airplane : 10
"""

# number of classes
K = len(set(y_train))

# calculate total number of classes
# for output layer
print("number of classes:", K)

"""We are going to use a Convolution Neural Network or CNN to train our model. It includes using a convolution layer in this which is Conv2d layer as well as pooling and normalization methods. Finally, we’ll pass it into a dense layer and the final dense layer which is our output layer. We are using ‘relu‘ activation function. The output layer uses a “softmax” function."""

# input layer
with tf.device('/device:GPU:0'):
  i = Input(shape=x_train[0].shape)
  x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)
  x = BatchNormalization()(x)
  x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
  x = BatchNormalization()(x)
  x = MaxPooling2D((2, 2))(x)

  x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
  x = BatchNormalization()(x)
  x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
  x = BatchNormalization()(x)
  x = MaxPooling2D((2, 2))(x)

  x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
  x = BatchNormalization()(x)
  x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
  x = BatchNormalization()(x)
  x = MaxPooling2D((2, 2))(x)

  x = Flatten()(x)
  x = Dropout(0.2)(x)

  # Hidden layer
  x = Dense(1024, activation='relu')(x)
  x = Dropout(0.2)(x)

  # last hidden layer i.e.. output layer
  x = Dense(K, activation='softmax')(x)

  model = Model(i, x)

  # model description
  model.summary()

"""Our model is now ready, it’s time to compile it. We are using model.compile() function to compile our model. For the parameters, we are using

adam optimizer \\
sparse_categorical_crossentropy as the loss function \\
metrics=[‘accuracy’]
"""

# Compile
model.compile(optimizer='adam',
			loss='sparse_categorical_crossentropy',
			metrics=['accuracy'])

"""Now let’s fit our model using model.fit() passing all our data to it. We are going to train our model till 50 epochs, it gives us a fair result"""

# Fit
r = model.fit(
x_train, y_train, validation_data=(x_test, y_test), epochs=50)

import matplotlib.pyplot as plt

# Accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(r.history['accuracy'], label='Training Accuracy')
plt.plot(r.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(r.history['loss'], label='Training Loss')
plt.plot(r.history['val_loss'], label='Validation Loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

"""# **Evaluation**"""

from sklearn.metrics import classification_report, f1_score, roc_auc_score, roc_curve, auc
from tensorflow.keras.utils import to_categorical
import numpy as np

# Predict the probabilities using the model
y_pred_probs = model.predict(x_test)

# Convert the probabilities to class labels
y_pred = np.argmax(y_pred_probs, axis=1)

# Class names from CIFAR-10
class_names = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

# 1. Classification Report
print(classification_report(y_test, y_pred, target_names=class_names))

# 2. Accuracy (from your model fit history)
print("Accuracy:", r.history['val_accuracy'][-1])

# 3. F1 Score (macro average will consider each class equally)
print("F1 Score:", f1_score(y_test, y_pred, average='macro'))

# 4. ROC AUC Score
# Convert y_test and y_pred to categorical (one-hot encoded) for multi-class ROC AUC
y_test_cat = to_categorical(y_test)
roc_auc = roc_auc_score(y_test_cat, y_pred_probs)
print("ROC AUC Score:", roc_auc)

# 5. ROC AUC Curve
fpr = {}
tpr = {}
thresh ={}
roc_auc_score_class = {}

plt.figure(figsize=(12,10))
for i in range(K): # number of classes
    fpr[i], tpr[i], thresh[i] = roc_curve(y_test_cat[:, i], y_pred_probs[:, i])
    roc_auc_score_class[i] = auc(fpr[i], tpr[i])
    plt.plot(fpr[i], tpr[i], label="Class {}: AUC={:.3f}".format(class_names[i], roc_auc_score_class[i]))
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC AUC Curve")
plt.legend(loc="lower right")
plt.show()